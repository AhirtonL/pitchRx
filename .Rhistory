names <- paste(names,  pitcher.name[j+1], sep = paste("' OR ", i, "_pitchers.full_name = '", sep = ""))
}
}
ids <- dbGetQuery(MLB, paste("SELECT DISTINCT id FROM ", i, "_pitchers WHERE ", i, "_pitchers.full_name = '", names, "'", sep = ""))
if (is.null(ids)) stop(paste("Sorry, none of these pitchers played a game in", i, sep = " "))
p.ids <- ids[1, "id"]
for (k in 1:dim(ids)[1]) {
if (!is.na(ids[k+1, "id"])) {
p.ids <- paste(p.ids,  ids[k+1, "id"], sep = paste(" OR ", i, "_atbats.pitcher = ", sep = ""))
}
}
return(p.ids)
#raw.pitches <- dbGetQuery(MLB, paste("SELECT DISTINCT * FROM ", i, "_pitchFX RIGHT JOIN ", i, "_atbats ON (", i, "_pitchFX.atbat_id = ", i, "_atbats.num AND ", i, "_pitchFX.url = ", i, "_atbats.url)  WHERE ", i, "_atbats.pitcher = ", p.ids, sep = ""))
#pitches <- cbind(raw.pitches, year = i)
#pitchFX <- rbind(pitchFX, pitches)
}
}
data <- visualize(first.date = "2011-01-01", last.date = Sys.Date(), pitcher.name = c("Justin Verlander", "Mariano Rivera"), pitch.type = c("FF", "CU"), zone = "all", time = 0.01)
visualize <- function(first.date = Sys.Date(), last.date = Sys.Date(), pitcher.name, pitch.type, zone = "all", time = 0.01, database = MLB){
#suppressMessages(library(gWidgets))
#options("guiToolkit"="RGtk2")
start <- as.Date(first.date)
end <- as.Date(last.date)
diff <- as.numeric(end - start)
dates <- start + c(0:diff) * days(1) #Create vector of dates from start date to end date
years <- year(dates)
pitchFX <- NULL
for (i in years) {
names <- pitcher.name[1]
for (j in 1:length(pitcher.name)) {
if (!is.na(pitcher.name[j+1])) {
names <- paste(names,  pitcher.name[j+1], sep = paste("' OR ", i, "_pitchers.full_name = '", sep = ""))
}
}
ids <- dbGetQuery(MLB, paste("SELECT DISTINCT id FROM ", i, "_pitchers WHERE ", i, "_pitchers.full_name = '", names, "'", sep = ""))
if (is.null(ids)) stop(paste("Sorry, none of these pitchers played a game in", i, sep = " "))
p.ids <- ids[1, "id"]
for (k in 1:dim(ids)[1]) {
if (!is.na(ids[k+1, "id"])) {
p.ids <- paste(p.ids,  ids[k+1, "id"], sep = paste(" OR ", i, "_atbats.pitcher = ", sep = ""))
}
}
raw.pitches <- dbGetQuery(MLB, paste("SELECT DISTINCT x0 FROM ", i, "_pitchFX RIGHT JOIN ", i, "_atbats ON (", i, "_pitchFX.atbat_id = ", i, "_atbats.num AND ", i, "_pitchFX.url = ", i, "_atbats.url)  WHERE ", i, "_atbats.pitcher = ", p.ids, sep = ""))
pitches <- cbind(raw.pitches, year = i)
pitchFX <- rbind(pitchFX, pitches)
}
}
data <- visualize(first.date = "2011-01-01", last.date = Sys.Date(), pitcher.name = c("Justin Verlander", "Mariano Rivera"), pitch.type = c("FF", "CU"), zone = "all", time = 0.01)
library(XML) #Load necessary packages for this package
library(plyr)
library(lubridate)
library(stringr)
library(reshape)
library(ggplot2)
library(animation)
library(RMySQL)
url <- "http://gd2.mlb.com/components/game/mlb/year_2011/month_04/day_15/
gid_2011_04_15_sfnmlb_arimlb_1/inning/inning_all.xml"
doc <- xmlParse(url)
url <- "http://gd2.mlb.com/components/game/mlb/year_2011/month_04/day_15/
gid_2011_04_15_sfnmlb_arimlb_1/inning/inning_all.xml"
doc <- xmlParse(url)
fix(url)
url <- "http://gd2.mlb.com/components/game/mlb/year_2011/month_04/day_15/gid_2011_04_15_sfnmlb_arimlb_1/inning/inning_all.xml"
doc <- xmlParse(url)
atbat <- getNodeSet(doc, "//atbat")
atbat.info <- llply(atbat, function(x) { xmlAttrs(x) })
atbat[1]
library(XML) #Load necessary packages for this package
library(plyr)
library(lubridate)
library(stringr)
library(reshape)
library(ggplot2)
library(animation)
library(RMySQL)
#Establish connection with MLB Database
drv <- dbDriver("MySQL")
MLB <- dbConnect(drv, user="root", password="Stats4Life", port=3306, dbname="MLB", host="127.0.0.1")
#Scraping work horse (for use strictly with package)
parseURLs <- function(urls) { #Function that greatly reduces time required to build tables.
docs <- NULL
url.vector <- NULL
for (i in urls) {
cat(i, "\n")
doc <- try_default(xmlParse(i), NULL, quiet = TRUE)
if (!is.null(doc)) {
docs <- c(docs, doc) #Keep non-empty documents
url.vector <- c(url.vector, i) #Keep urls that have data
}
}
return(docs)
}
scrapePitchFX <- function(start = "2012-01-01", end = Sys.Date()) { #make fields flexible?
first.date <- paste("('", start, "')", sep = "")
if (year(start) < 2005) stop("Not only is pitchFX data not avaliable before 2008, data on each game isn't complete until 2005")
if (year(start) < 2008) stop("Warning: pitchFX data wasn't recorded consistently until 2008. Please consider a later start date.")
last.date <- paste("('", end, "')", sep = "")
if (end > Sys.Date()) stop("Sorry, I can't scrape data on the future!")
urls <- dbGetQuery(MLB, paste("SELECT url FROM all_games WHERE all_games.date >= ", first.date, "AND all_games.date <=", last.date, sep = ""))
t <- urls[,"url"]
docs <- parseURLs(urls = t)
return(docs)
#all.tags <- c("ax", "ay", "az", "break_angle", "break_length", "break_y", "cc", "des",
#              "end_speed", "id", "mt", "nasty", "on_1b", "on_2b", "on_3b", "pfx_x", "pfx_z", "pitch_type",
#              "px", "pz", "spin_dir", "spin_rate", "start_speed", "sv_id", "sz_bot", "sz_top",
#              "tfs", "tfs_zulu", "type", "type_confidence", "vx0", "vy0", "vz0",
#              "x", "x0", "y", "y0", "z0", "zone")
#rawTable <- docsToDataFrame(urls = t, tags = all.tags)
#How do I write table in proper directory? What format should I use?
}
docs <- scrapePitchFX()
fix(doc)
library(devtools)
install_github('pitchFX', 'cpsievert')
?devtools
?ddply
library(plyr)
?plyr
?ddply
head(baseball)
install_github('pitchFX', 'cpsievert')
library(pitchFX)
?pitchFX
?scrapePitchFX
scrapePitchFX()
install_github('gghammock', 'heike')
library(gghammock)
?gghammock
gghammock()
?pitchFX
?gghammock
install_github('pitchFX', 'cpsievert')
install_github('pitchFX', 'cpsievert')
install_github('pitchFX', 'cpsievert')
library(pitchFX)
?pitchFX
?scrapePitchFX
library(devtools)
install_github('pitchFX', 'cpsievert')
install_github('pitchFX', 'cpsievert')
install_github('pitchFX', 'cpsievert')
library(pitchFX)
?pitchFX
?scrapePitchFX
library(devtools)
install_github('pitchFX', 'cpsievert')
library(pitchFX)
?pitchFX
?scrapePitchFX
ptm <- proc.time()
data <- scrapePitchFX(start = "2011-05-01", end = "2011-05-01")
ptm
library(RMySQL)
drv <- dbDriver("MySQL")
MLB <- dbConnect(drv, user="root", password="Stats4Life", port=3306, dbname="MLB", host="127.0.0.1")
MLB <- dbConnect(drv, user="root", password="Stats4Life", port=3306, dbname="MLB", host="127.0.0.1")
library(devtools)
install_github('pitchRx', 'cpsievert')
library(pitchRx)
?urlsToDataFrame
?scrapePitchFX
branch <- "http://gd2.mlb.com/components/game/mlb/twitter/"
doc <- htmlParse(branch)
extensions <- str_extract_all(xpathSApply(doc, "//a[@href]", xmlGetAttr, "href"), "([a-z]+)InsiderTweets.xml.([0-9]+)")
twitter.urls <- paste(branch, extensions[llply(extensions, length) > 0], sep = "")
twitter.docs <- xmlParse(twitter.urls)
head(twitter.urls)
fix(twitter.urls)
twitter.docs <- NULL
url.vector <- NULL
for (i in twitter.urls) {
cat(i, "\n")
doc <- try_default(xmlParse(i), NULL, quiet = TRUE)
if (!is.null(doc)) {
docs <- c(docs, doc) #Keep non-empty documents
url.vector <- c(url.vector, i) #Keep urls that have content
}
}
twitter.docs <- NULL
url.vector <- NULL
for (i in twitter.urls) {
cat(i, "\n")
doc <- try_default(xmlParse(i), NULL, quiet = TRUE)
if (!is.null(doc)) {
twitter.docs <- c(twitter.docs, doc) #Keep non-empty documents
url.vector <- c(url.vector, i) #Keep urls that have content
}
}
twitter.docs <- NULL
url.vector <- NULL
for (i in twitter.urls[1:5]) {
cat(i, "\n")
doc <- try_default(xmlParse(i), NULL, quiet = TRUE)
if (!is.null(doc)) {
twitter.docs <- c(twitter.docs, doc) #Keep non-empty documents
url.vector <- c(url.vector, i) #Keep urls that have content
}
}
frames <- llply(twitter.docs, function(x) { xmlToDataFrame(x) })
frames
frames <- llply(twitter.docs, function(x) { xmlToDataFrame(x) })
all.fields <- unique(unlist(llply(frames, names)))
missing <- llply(frames, function(x) { all.fields[!(all.fields %in% names(x))] })
dfs <- mapply(function(x, y) {
#missing <- y[!(y %in% names(x))]
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
z <- list(data.frame(x, t(rep(NA, length(y)))))
names(z[[1]]) <- c(names(z[[1]]), y)
#names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(missing)
z
} else {
x
}
}, frames, missing)
data <- NULL
for (i in dfs) {
while (!is.data.frame(i)) {
i <- i[[1]]
}
data <- rbind(data, i)
}
data <- NULL
for (i in dfs) {
browser()
while (!is.data.frame(i)) {
i <- i[[1]]
}
data <- rbind(data, i)
}
n
!is.data.frame(i)
n
n
n
!is.data.frame(i)
str(dfs)
dfs <- mapply(function(x, y) {
#missing <- y[!(y %in% names(x))]
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
z <- list(data.frame(x, t(rep(NA, length(y)))))
names(z[[1]]) <- c(names(z[[1]]), y)
#names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(missing)
z
} else {
x
}
}, frames, missing)
Q
dfs <- mapply(function(x, y) {
#missing <- y[!(y %in% names(x))]
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
z <- list(data.frame(x, t(rep(NA, length(y)))))
names(z[[1]]) <- c(names(z[[1]]), y)
#names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(missing)
z
} else {
x
}
}, frames, missing)
dfs
dfs <- mapply(function(x, y) {
#missing <- y[!(y %in% names(x))]
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
z <- list(data.frame(x, t(rep(NA, length(y)))))
#names(z[[1]]) <- c(names(z[[1]]), y)
names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(missing)
z
} else {
x
}
}, frames, missing)
str(dfs)
dfs <- mapply(function(x, y) {
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
z <- list(data.frame(x, t(rep(NA, length(y)))))
names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(y)
z
} else {
x
}
}, frames, missing)
str(dfs)
frames
?mapply
word <- function(C,k) paste(rep.int(C,k), collapse = '')
utils::str(mapply(word, LETTERS[1:6], 6:1, SIMPLIFY = FALSE)
)
word
?expand
?aggregate
?assemble
assemble <- function(x, y) {
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
x[y] <- NA
#z <- list(data.frame(x, t(rep(NA, length(y)))))
#names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(y)
#z
} else {
x
}
}
dfs <- mapply(assemble, frames, missing)
str(dfs)
assemble <- function(x, y) {
if (length(y) > 0) {
#options(stringsAsFactors = FALSE) doesn't work?
x[y] <- NA
list(x)
#z <- list(data.frame(x, t(rep(NA, length(y)))))
#names(z[[1]])[!(names(z[[1]]) %in% names(x))] <- as.character(y)
#z
} else {
list(x)
}
}
dfs <- mapply(assemble, frames, missing)
str(dfs)
dfs2 <- ldply(dfs, function(x) { x })
str(dfs)
dfs2 <- ldply(dfs, rbind)
str(dfs)
rbind(dfs)
?indentity
?identity
dfs2 <- ldply(dfs, identity)
str(dfs2)
setwd("~/Desktop/github/local/pitchRx")
document(".")
document(".")
document(".")
install(".") #install the package
branch <- "http://gd2.mlb.com/components/game/mlb/twitter/"
doc <- htmlParse(branch)
extensions <- str_extract_all(xpathSApply(doc, "//a[@href]", xmlGetAttr, "href"), "([a-z]+)InsiderTweets.xml.([0-9]+)")
twitter.urls <- paste(branch, extensions[llply(extensions, length) > 0], sep = "")
#Scraping the files into a data frame
tweets <- urlsToDataFrame(urls = twitter.urls, tables = list(status = NULL), use.values = TRUE)
str(tweets)
tweets <- urlsToDataFrame(urls = twitter.urls[1:3], tables = list(status = NULL), use.values = TRUE)
tweets <- urlsToDataFrame(urls = twitter.urls[10:12], tables = list(status = NULL), use.values = TRUE)
tweets <- urlsToDataFrame(urls = twitter.urls[10:15], tables = list(status = NULL), use.values = TRUE)
install(".") #install the package
tweets <- urlsToDataFrame(urls = twitter.urls, tables = list(status = NULL), use.values = TRUE)
n
n
n
n
n
n
n
n
tweets <- urlsToDataFrame(urls = twitter.urls, tables = list(status = NULL), use.values = TRUE)
n
n
n
n
n
n
n
n
install(".") #install the package
tweets <- urlsToDataFrame(urls = twitter.urls, tables = list(status = NULL), use.values = TRUE)
n
n
n
n
n
n
n
?return
document(".")
getNodeSet(doc, "//a")
extensions <- str_extract_all(getNodeSet(doc, "//a"), "([a-z]+)InsiderTweets.xml.([0-9]+)")
xpathApply(getNodeSet(doc, "//a"), xmlValue)
xpathSApply(doc, xmlValue)
xpathSApply(doc, xmlGetValue)
?xmlValue
xmlValue(getNodeSet(doc, "//a"))
unlist(getNodeSet(doc, "//a"))
str(unlist(getNodeSet(doc, "//a")))
str(as.character(getNodeSet(doc, "//a")))
llply(nodes, xmlValue)
nodes <- getNodeSet(doc, "//a")
llply(nodes, xmlValue)
branch <- "http://gd2.mlb.com/components/game/mlb/twitter/"
doc <- htmlParse(branch)
nodes <- getNodeSet(doc, "//a")
extensions <- str_extract_all(llply(nodes, xmlValue), "([a-z]+)InsiderTweets.xml.([0-9]+)")
?values
values <- llply(nodes, xmlValue)
extensions <- str_extract_all(values, "([a-z]+)InsiderTweets.xml.([0-9]+)")
str(values)
values <- sapply(nodes, xmlValue)
extensions <- str_extract_all(values, "([a-z]+)InsiderTweets.xml.([0-9]+)")
twitter.urls <- paste(branch, extensions[llply(extensions, length) > 0], sep = "")
head(twitter.urls)
extensions <- c(str_extract_all(values, "([a-z]+)InsiderTweets.xml"), str_extract_all(values, "([a-z]+)InsiderTweets.xml.([0-9]+)"))
twitter.urls <- paste(branch, extensions[llply(extensions, length) > 0], sep = "")
head(twitter.urls)
document(".")
install(".")
View(tweets)
url <- "http://gd2.mlb.com/components/game/mlb/notifications.xml"
doc <- xmlParse(url)
str(doc)
getNodeSet(doc,"//alerts")
alerts <- getNodeSet(doc,"//alerts")
xmlChildren(alerts)
xmlChildren(alerts)
attr(xmlChildren(alerts), "type")
?try
?try_default
try(xmlChildren(alerts))
"try-error" %in% try(xmlChildren(alerts))
"try-error" %in% class(try(xmlChildren(alerts)))
llply(node, xmlChildren)
node <- getNodeSet(doc,"//alerts")
llply(node, xmlChildren)
str(llply(node, xmlChildren))
try.again <- function(node) {
t <- try(xmlChildren(node))
if ("try-error" %in% class(t)) t <- llply(node, try.again)
}
try.again(node)
try.again <- function(node) {
browser()
t <- try(xmlChildren(node))
if ("try-error" %in% class(t)) t <- llply(node, try.again)
}
try.again(node)
n
n
n
n
Q
try.again <- function(node) {
browser()
t <- try_default(xmlChildren(node), NULL, quiet = TRUE)
if ("try-error" %in% class(t)) t <- llply(node, try.again)
}
try.again(node)
n
n
n
n
llply(node, xmlChildren)
str(llply(node, xmlChildren))
kids <- llply(node, xmlChildren))
kids <- llply(node, xmlChildren)
kids[[1]]
llply(kids, xmlChildren)
vignette("XML")
addChildren(node)
?addChildren
b = newXMLNode("bob", namespace = c(r = "http://www.r-project.org", omg = "http://www.omegahat.org"))
b
addChildren(b, newXMLNode("el", "Red", "Blue", "Green",
attrs = c(lang ="en")))
b = newXMLNode("bob", namespace = c(r = "http://www.r-project.org", omg = "http://www.omegahat.org"))
xmlSize(b)
addChildren(b, newXMLNode("el", "Red", "Blue", "Green",
attrs = c(lang ="en")))
xmlSize(b)
node <- getNodeSet(doc,"//alerts")
xmlSize(node)
kids <- llply(node, xmlChildren)
xmlSize(kids)
kids2 <- llply(kids, xmlChildren)
kids
kids[[1]][[1]]
xmlSize(kids[[1]][[1]])
dtdFile <- system.file("exampleData","foo.dtd", package="XML")
foo.dtd <- parseDTD(dtdFile)
foo.dtd
tmp <- dtdElement("variable", foo.dtd)
xmlAttrs(tmp)
dtdFile
xmlParse(dtdFile)
url <- "http://gd2.mlb.com/components/game/mlb/year_2009/month_07/day_18/gid_2009_07_18_minmlb_texmlb_1/batters/285078.xml"
urlsToDataFrame(url, tables = list(Player = NULL), add.children = TRUE)
library(RMySQL)
drv <- dbDriver("MySQL")
MLB <- dbConnect(drv, user="root", password="Stats4Life", port=3306, dbname="MLB", host="127.0.0.1")
runners <- dbReadTable(MLB, name = "runner")
dbWriteTable(MLB, value = runners, name = "runners", row.names = FALSE, append = TRUE)
umpires <- dbReadTable(MLB, name = "umpires")
umpires$url <- gsub("players.xml", "inning/inning_all.xml", umpires$url_player)
dbWriteTable(MLB, value = umpires, name = "umpire", row.names = FALSE, append = TRUE)
coaches <- dbReadTable(MLB, name = "coaches")
coaches$url <- gsub("players.xml", "inning/inning_all.xml", coaches$url_player)
dbWriteTable(MLB, value = coaches, name = "coach", row.names = FALSE, append = TRUE)
branch <- "http://gd2.mlb.com/components/game/mlb/twitter/"
doc <- htmlParse(branch)
nodes <- getNodeSet(doc, "//a")
values <- sapply(nodes, xmlValue)
extensions <- str_extract_all(values, "([a-z]+)InsiderTweets.xml.([0-9]+)")
twitter.urls <- paste(branch, extensions[llply(extensions, length) > 0], sep = "")
tweets <- urlsToDataFrame(urls = twitter.urls, tables = list(status = NULL), use.values = TRUE, add.children = TRUE)
tweets <- urlsToDataFrame(urls = twitter.urls[1:20], tables = list(status = NULL), use.values = TRUE, add.children = TRUE)
tweets
View(tweets)
games <- dbReadTable(MLB, name = "games")
dbWriteTable(MLB, value = games, name = "game", row.names = FALSE, append = TRUE)
head(games$url)
dbWriteTable(MLB, value = games, name = "game", row.names = FALSE, append = TRUE)
